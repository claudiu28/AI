{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T18:59:16.672855Z",
     "start_time": "2025-04-09T18:59:10.649724Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "class MyLogisticReggresion:\n",
    "    def __init__(self, learning_rate=0.05, epochs=5000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.w = None\n",
    "        self.free = 0\n",
    "\n",
    "    # Ïƒ(z)= 1 / 1 + e ^ (-z)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    @staticmethod\n",
    "    def transpose(matrix):\n",
    "        return [[matrix[i][j] for i in range(len(matrix))] for j in range(len(matrix[0]))]\n",
    "    \n",
    "    @staticmethod\n",
    "    def mat_vec_dot(transposed_matrix, vector):\n",
    "        result = []\n",
    "        for row in transposed_matrix:\n",
    "            s = 0\n",
    "            for i in range(len(vector)):\n",
    "                s += row[i] * vector[i]\n",
    "            result.append(s)\n",
    "        return result\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        n_samples, n_features = x.shape\n",
    "        self.w = [0.0 for _ in range(n_features)]\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            linear_model = [self.free + sum(self.w[j] * x[i][j] for j in range(n_features)) for i in range(n_samples)]\n",
    "            pred = [self.sigmoid(z) for z in linear_model]\n",
    "            \n",
    "            errors = [pred[i] - y[i] for i in range(n_samples)]\n",
    "            \n",
    "            x_t = self.transpose(x)\n",
    "            \n",
    "            w_gradient = self.mat_vec_dot(x_t, errors)\n",
    "            w_gradient = [g / n_samples for g in w_gradient]\n",
    "            \n",
    "            free_gradient = sum(errors) / n_samples\n",
    "            \n",
    "            self.w = [self.w[i] - self.learning_rate * w_gradient[i] for i in range(n_features)]\n",
    "            self.free -= self.learning_rate * free_gradient\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        linear_model = np.dot(x, self.w) + self.free\n",
    "        predictions = self.sigmoid(linear_model)\n",
    "        return (predictions >= 0.5).astype(int)\n",
    "\n",
    "def load_data(file_name):\n",
    "    data = []\n",
    "    with open(file_name) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            radius = float(row[2])\n",
    "            texture = float(row[3])\n",
    "            if row[1] == 'M':\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            data.append([[radius, texture], label])\n",
    "    x = [d[0] for d in data]\n",
    "    y = [d[1] for d in data]\n",
    "    return x, y\n",
    "\n",
    "file = '../data/wdbc.data'\n",
    "inputs, outputs = load_data(file)\n",
    "feature1 = [ex[0] for ex in inputs]\n",
    "feature2 = [ex[1] for ex in inputs]\n",
    "\n",
    "np.random.seed(5)\n",
    "indexes = [i for i in range(len(inputs))]\n",
    "trainSample = np.random.choice(indexes, int(0.8 * len(inputs)), replace=False)\n",
    "testSample = [i for i in indexes if not i in trainSample]\n",
    "\n",
    "trainInputs = [inputs[i] for i in trainSample]\n",
    "trainOutputs = [outputs[i] for i in trainSample]\n",
    "testInputs = [inputs[i] for i in testSample]\n",
    "testOutputs = [outputs[i] for i in testSample]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "trainInputs = scaler.fit_transform(trainInputs)\n",
    "testInputs = scaler.transform(testInputs)\n",
    "\n",
    "feature1train = [ex[0] for ex in trainInputs]\n",
    "feature2train = [ex[1] for ex in trainInputs]\n",
    "feature1test = [ex[0] for ex in testInputs]\n",
    "feature2test = [ex[1] for ex in testInputs]\n",
    "\n",
    "regressor = MyLogisticReggresion()\n",
    "regressor.fit(trainInputs, trainOutputs)\n",
    "\n",
    "w0, w1, w2 = regressor.free, regressor.w[0], regressor.w[1]\n",
    "print(f'the learnt model: f(x) = {w0} + {w1} * x1 + {w2} * x2')\n",
    "\n",
    "computedTestOutputs = regressor.predict(testInputs)\n",
    "new_datail = scaler.transform([[18, 10]])\n",
    "rez = regressor.predict(new_datail)\n",
    "print(\"Noua leziune este:\", \"Maligna\" if rez[0] == 1 else \"Benigna\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the learnt model: f(x) = -0.9477163231738559 + 4.294968291614496 * x1 + 1.0172143426534384 * x2\n",
      "Noua leziune este: Maligna\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8bff7b60ede7c7fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T17:46:49.612788Z",
     "start_time": "2025-04-08T17:46:49.609786Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e5f730937be1eacd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
