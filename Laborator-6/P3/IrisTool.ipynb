{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T19:02:14.470338Z",
     "start_time": "2025-04-09T19:02:04.577160Z"
    }
   },
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class MySoftmaxRegression:\n",
    "    def __init__(self, learning_rate=0.05, epochs=10000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.w = None  \n",
    "        self.free = None \n",
    "\n",
    "    # practic probabiltae sa fie una dintre cele 3 cat la suta sa fie unu 2 sau 0  \n",
    "    @staticmethod\n",
    "    def softmax(z):\n",
    "        result = []\n",
    "        for r in z:\n",
    "            max_val = max(r)\n",
    "            exp_row = [math.exp(val - max_val) for val in r]\n",
    "            sum_exp = sum(exp_row)\n",
    "            result.append([val / sum_exp for val in exp_row])\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def transpose(matrix):\n",
    "        return [[matrix[i][j] for i in range(len(matrix))] for j in range(len(matrix[0]))]\n",
    "\n",
    "    @staticmethod\n",
    "    def mat_vec_dot(matrix, vector):\n",
    "        result = []\n",
    "        for r in matrix:\n",
    "            s = 0\n",
    "            for i in range(len(vector)):\n",
    "                s += r[i] * vector[i]\n",
    "            result.append(s)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def mul_matrix(a, b):\n",
    "        result = []\n",
    "        for i in range(len(a)):\n",
    "            r = []\n",
    "            for j in range(len(b[0])):\n",
    "                val = sum(a[i][k] * b[k][j] for k in range(len(b)))\n",
    "                r.append(val)\n",
    "            result.append(r)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def subtract_matrix(a, b):\n",
    "        return [[a[i][j] - b[i][j] for j in range(len(a[0]))] for i in range(len(a))]\n",
    "\n",
    "    @staticmethod\n",
    "    def scalar_divide_matrix(matrix, s):\n",
    "        return [[val / s for val in r] for r in matrix]\n",
    "\n",
    "    @staticmethod\n",
    "    def scalar_subtract_matrix(a, b, lr):\n",
    "        return [[a[i][j] - lr * b[i][j] for j in range(len(a[0]))] for i in range(len(a))]\n",
    "\n",
    "    @staticmethod\n",
    "    def add_free(matrix, free):\n",
    "        return [[matrix[i][j] + free[0][j] for j in range(len(free[0]))] for i in range(len(matrix))]\n",
    "\n",
    "    @staticmethod\n",
    "    def to_bin(y, num_classes):\n",
    "        return [[1 if i == label else 0 for i in range(num_classes)] for label in y]\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        n_samples = len(x)\n",
    "        n_features = len(x[0])\n",
    "        values = max(y) + 1\n",
    "\n",
    "        self.w = [[0.0 for _ in range(values)] for _ in range(n_features)]\n",
    "        self.free = [[0.0 for _ in range(values)]]\n",
    "        y_one_hot = self.to_bin(y, values)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            logits = self.add_free(self.mul_matrix(x, self.w), self.free)\n",
    "            probs = self.softmax(logits)\n",
    "            error = self.subtract_matrix(probs, y_one_hot)\n",
    "\n",
    "            x_t = self.transpose(x)\n",
    "            dw = self.mul_matrix(x_t, error)\n",
    "            dw = self.scalar_divide_matrix(dw, n_samples)\n",
    "\n",
    "            db = [[sum(error[i][j] for i in range(n_samples)) / n_samples for j in range(values)]]\n",
    "\n",
    "            self.w = self.scalar_subtract_matrix(self.w, dw, self.learning_rate)\n",
    "            self.free = self.scalar_subtract_matrix(self.free, db, self.learning_rate)\n",
    "            \n",
    "        return self.free, self.w\n",
    "\n",
    "    def predict(self, x):\n",
    "        logits = self.add_free(self.mul_matrix(x, self.w), self.free)\n",
    "        probs = self.softmax(logits)\n",
    "        predictions = []\n",
    "        for r in probs:\n",
    "            max_index = 0\n",
    "            max_val = r[0]\n",
    "            for i in range(1, len(r)):\n",
    "                if r[i] > max_val:\n",
    "                    max_val = r[i]\n",
    "                    max_index = i\n",
    "            predictions.append(max_index)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def load_data(file_name):\n",
    "    data = []\n",
    "    with open(file_name) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for r in csv_reader:\n",
    "            sepal_length = float(r[0])\n",
    "            sepal_width = float(r[1])\n",
    "            petal_length = float(r[2])\n",
    "            petal_width = float(r[3]) \n",
    "            if r[4] == 'Iris-setosa':\n",
    "                label = 0\n",
    "            elif r[4] == 'Iris-versicolor':\n",
    "                label = 1\n",
    "            else:  \n",
    "                label = 2\n",
    "            features = [sepal_length, sepal_width, petal_length, petal_width]\n",
    "            data.append([features, label])\n",
    "            \n",
    "    x = [d[0] for d in data]\n",
    "    y = [d[1] for d in data]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "file = \"../data/iris.data\"\n",
    "inputs, outputs = load_data(file)\n",
    "\n",
    "feature1 = [ex[0] for ex in inputs]\n",
    "feature2 = [ex[1] for ex in inputs]\n",
    "feature3 = [ex[2] for ex in inputs]\n",
    "feature4 = [ex[3] for ex in inputs]\n",
    "\n",
    "np.random.seed(5)\n",
    "indexes = [i for i in range(len(inputs))]\n",
    "trainSample = np.random.choice(indexes, int(0.8 * len(inputs)), replace=False)\n",
    "testSample = [i for i in indexes if not i in trainSample]\n",
    "\n",
    "trainInputs = [inputs[i] for i in trainSample]\n",
    "trainOutputs = [outputs[i] for i in trainSample]\n",
    "testInputs = [inputs[i] for i in testSample]\n",
    "testOutputs = [outputs[i] for i in testSample]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "trainInputs = scaler.fit_transform(trainInputs)\n",
    "testInputs = scaler.transform(testInputs)\n",
    "\n",
    "feature1train = [ex[0] for ex in trainInputs]\n",
    "feature2train = [ex[1] for ex in trainInputs]\n",
    "feature3train = [ex[2] for ex in trainInputs]\n",
    "feature4train = [ex[3] for ex in trainInputs]\n",
    "feature1test = [ex[0] for ex in testInputs]\n",
    "feature2test = [ex[1] for ex in testInputs]\n",
    "feature3test = [ex[2] for ex in testInputs]\n",
    "feature4test = [ex[3] for ex in testInputs]\n",
    "\n",
    "regressor = MySoftmaxRegression()\n",
    "w0, w = regressor.fit(trainInputs, trainOutputs)\n",
    "print(f'the learnt model: f(x) = {w0} + {w[0]} * x1 + {w[1]} * x2+ {w[2]} * x3 + {w[3]} * x4')\n",
    "print(\"Biasuri (free):\", regressor.free)\n",
    "print(\"Greutăți (w):\")\n",
    "for i, row in enumerate(regressor.w):\n",
    "    print(f\"  x{i}: {row}\")\n",
    "computedTestOutputs = regressor.predict(testInputs)\n",
    "new_datail = scaler.transform([[5.35,3.85,1.25,0.4]])\n",
    "pred = regressor.predict(new_datail)\n",
    "print(\"Probabilități pentru fiecare clasă:\", pred[0])\n",
    "\n",
    "print(\"Noua floare este din specia:\", \"Iris-setosa\" if pred == 0 else \n",
    "      \"Iris-versicolor\" if pred == 1 else \"Iris-virginica\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the learnt model: f(x) = [[-0.33263330217448506, 3.8841747643681894, -3.5515414621937054]] + [np.float64(-1.8108150348896292), np.float64(1.1851075198031353), np.float64(0.6257075150865025)] * x1 + [np.float64(2.276341190800492), np.float64(-0.6133260171729873), np.float64(-1.6630151736275203)] * x2+ [np.float64(-3.2293291476294304), np.float64(-0.9417360026766695), np.float64(4.171065150306081)] * x3 + [np.float64(-3.1381978453947235), np.float64(-1.3545164103929324), np.float64(4.492714255787706)] * x4\n",
      "Biasuri (free): [[-0.33263330217448506, 3.8841747643681894, -3.5515414621937054]]\n",
      "Greutăți (w):\n",
      "  x0: [np.float64(-1.8108150348896292), np.float64(1.1851075198031353), np.float64(0.6257075150865025)]\n",
      "  x1: [np.float64(2.276341190800492), np.float64(-0.6133260171729873), np.float64(-1.6630151736275203)]\n",
      "  x2: [np.float64(-3.2293291476294304), np.float64(-0.9417360026766695), np.float64(4.171065150306081)]\n",
      "  x3: [np.float64(-3.1381978453947235), np.float64(-1.3545164103929324), np.float64(4.492714255787706)]\n",
      "Probabilități pentru fiecare clasă: 0\n",
      "Noua floare este din specia: Iris-virginica\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T19:02:14.476029Z",
     "start_time": "2025-04-09T19:02:14.473770Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b2d5ffc4466b61e4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
